# ENVIRONMENT PARAMETERS
ENV=prod
# dev, qa, prod
REGION_NAME=region-name
# us-east-1, sa-east-1
DATA_STORAGE_ENV=S3
# filesystem, S3
MODEL_STORAGE_ENV=S3
# filesystem, S3, mlflow
ETL_ENV=lambda
# local, docker-compose, lambda
MODEL_BUILDING_ENV=sagemaker
# local, docker-compose, sagemaker
APP_ENV=local
# local, docker-compose, EC2
DOCKER_REPOSITORY_TYPE=ECR
# dockerhub, ECR


# SAGEMAKER PARAMETERS
SM_INPUT_DEST=/opt/ml/processing/input
SM_OUTPUT_SOURCE=/opt/ml/processing/output
SM_S3_DATA_TYPE=S3Prefix
# ManifestFile | S3Prefix
SM_INPUT_MODE=File
# Pipe | File
SM_DATA_DISTRIBUTION_TYPE=FullyReplicated
# FullyReplicated | ShardedByS3Key
SM_S3_COMPRESSION_TYPE=None
# None | Gzip
SM_APP_MANAGED=True
# True | False
SM_S3_UPLOAD_MODE=EndOfJob
# Continuous | EndOfJob

PROCESSING_INSTANCE_TYPE=ml.t3.large
PROCESSING_INSTANCE_COUNT=1
PROCESSING_VOLUME_SIZE=30
PROCESSING_MAX_RUNTIME=300

TUNING_INSTANCE_TYPE=ml.t3.large
TUNING_INSTANCE_COUNT=1
TUNING_VOLUME_SIZE=30
TUNING_MAX_RUNTIME=300

TRAINING_INSTANCE_TYPE=ml.t3.large
TRAINING_INSTANCE_COUNT=1
TRAINING_VOLUME_SIZE=30
TRAINING_MAX_RUNTIME=300

EVALUATING_INSTANCE_TYPE=ml.t3.large
EVALUATING_INSTANCE_COUNT=1
EVALUATING_VOLUME_SIZE=30
EVALUATING_MAX_RUNTIME=300

INFERENCE_INSTANCE_TYPE=ml.t3.large
INFERENCE_INSTANCE_COUNT=1
INFERENCE_VOLUME_SIZE=30
INFERENCE_MAX_RUNTIME=300

DEFAULT_INSTANCE_TYPE=ml.t3.large
DEFAULT_INSTANCE_COUNT=1
DEFAULT_VOLUME_SIZE=30
DEFAULT_MAX_RUNTIME=300


# DEPLOYMENT PARAMETERS
INFERENCE_HOST=0.0.0.0
INFERENCE_PORT=8080
WEBAPP_HOST=localhost
# 0.0.0.0, localhost
WEBAPP_PORT=8501


# PATHS
RAW_DATASETS_PATH=datasets/raw
PROCESSING_DATASETS_PATH=datasets/processing
INFERENCE_PATH=inference
TRANSFORMERS_PATH=transformers
MODELS_PATH=models
SCHEMAS_PATH=schemas
MOCK_PATH=mock


# OTHERS
SEED=23111997